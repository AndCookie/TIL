{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db26288",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "780e2711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>작성일</th>\n",
       "      <th>별점</th>\n",
       "      <th>제목_본문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toto</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazing product.I travel a lot, and I frequent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toto</td>\n",
       "      <td>2022-08-28</td>\n",
       "      <td>5</td>\n",
       "      <td>Husband says best gift ever!.I purchased this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toto</td>\n",
       "      <td>2018-07-25</td>\n",
       "      <td>3</td>\n",
       "      <td>Leakage problem fix.7/24/18First of, I did not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biobidet</td>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>3</td>\n",
       "      <td>Loved it for the few days it has worked..We bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>biobidet</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>5</td>\n",
       "      <td>It Works Beautifully.It does everything it say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        회사명        작성일  별점                                              제목_본문\n",
       "0      toto 2022-01-25   5  Amazing product.I travel a lot, and I frequent...\n",
       "1      toto 2022-08-28   5  Husband says best gift ever!.I purchased this ...\n",
       "2      toto 2018-07-25   3  Leakage problem fix.7/24/18First of, I did not...\n",
       "3  biobidet 2021-12-21   3  Loved it for the few days it has worked..We bo...\n",
       "4  biobidet 2021-03-01   5  It Works Beautifully.It does everything it say..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Combined_Review_origin = pd.read_excel('combined_review.xlsx')\n",
    "Combined_Review_origin.shape # (2157,11)\n",
    "Combined_Review_origin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba4438a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31198 entries, 0 to 31197\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   회사명     31198 non-null  object        \n",
      " 1   작성일     31198 non-null  datetime64[ns]\n",
      " 2   별점      31198 non-null  int64         \n",
      " 3   제목_본문   31198 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(2)\n",
      "memory usage: 975.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# 카피본 떠놓고 시작하기\n",
    "combined_review = Combined_Review_origin.copy()\n",
    "combined_review.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3fc13",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a5fe300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Amazing product.I travel a lot, and I frequent...\n",
       "1        Husband says best gift ever!.I purchased this ...\n",
       "2        Leakage problem fix.7/24/18First of, I did not...\n",
       "3        Loved it for the few days it has worked..We bo...\n",
       "4        It Works Beautifully.It does everything it say...\n",
       "                               ...                        \n",
       "31193    Good product.I installed BB-2000 to replace my...\n",
       "31194    Fantastic product.We have had our current For ...\n",
       "31195    Great product.I bought this product about two ...\n",
       "31196    Straight forward installation.This is  second ...\n",
       "31197    Wouldn’t be without it.We just recently purcha...\n",
       "Name: 제목_본문, Length: 31198, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_review['제목_본문']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bcb5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91faf8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfe508b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7bbe2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 경고 메세지 출력 안하기\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "182ed0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') # 구두점 사전 다운로드 / 구두점: 글의 여러 가지 경계를 구분하기 위해 사용되는 반점(,), 온점(.), 물음표(?), 쌍점( : ), 쌍반점(;), 줄표(--), 붙임표(-) 등의 부호\n",
    "nltk.download('punkt') # 불용어 사전 다운로드 / 불용어: 문장을 분석하는데 큰 의미가 없는 문자열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63ea6387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Download stopwords\n",
    "# nltk.download('stopwords')\n",
    "# stop_words = stopwords.words(\"english\")\n",
    "\n",
    "# # Define preprocess function\n",
    "# def preprocess(text):\n",
    "#     # Convert to lowercase\n",
    "#     text = text.lower()\n",
    "#     # Remove non-alphanumeric characters and punctuation\n",
    "#     text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "#     # Remove words with length less than 2\n",
    "#     text = \" \".join([word for word in text.split() if len(word) > 1])\n",
    "#     return text\n",
    "\n",
    "# # Define a function that maps review scores to three labels\n",
    "# def score_to_label(score):\n",
    "#     if score >= 4:\n",
    "#         return \"positive\"\n",
    "#     elif score == 3:\n",
    "#         return \"neutral\"\n",
    "#     else:\n",
    "#         return \"negative\"\n",
    "\n",
    "# # Load dataset\n",
    "# combined_review = pd.read_excel('combined_review.xlsx')\n",
    "\n",
    "# # Preprocess reviews\n",
    "# combined_review['제목_본문'] = combined_review['제목_본문'].apply(preprocess)\n",
    "# combined_review['별점'] = combined_review['별점'].apply(score_to_label)\n",
    "\n",
    "# # Load the pre-trained BERT model and tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=3)\n",
    "\n",
    "# # Tokenize the reviews and create input sequences\n",
    "# reviews = combined_review['제목_본문'].values\n",
    "# labels = combined_review['별점'].values\n",
    "\n",
    "# input_ids = []\n",
    "# attention_masks = []\n",
    "\n",
    "# for review in reviews:\n",
    "#     encoded_dict = tokenizer.encode_plus(\n",
    "#                         review,\n",
    "#                         add_special_tokens=True,\n",
    "#                         max_length=128,\n",
    "#                         pad_to_max_length=True,\n",
    "#                         return_attention_mask=True,\n",
    "#                         return_tensors='pt',\n",
    "#                         stopwords=stop_words,\n",
    "#                         truncation=True\n",
    "#                    )\n",
    "#     input_ids.append(encoded_dict['input_ids'])\n",
    "#     attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# input_ids = torch.cat(input_ids, dim=0)\n",
    "# attention_masks = torch.cat(attention_masks, dim=0)\n",
    "# labels = torch.tensor(labels)\n",
    "\n",
    "# # Split the dataset into training and validation sets\n",
    "# dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# # Create data loaders for training and validation sets\n",
    "# batch_size = 32\n",
    "# train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "# val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e5b9fe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "# Define preprocess function\n",
    "def preprocess(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove non-alphanumeric characters and punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    # Remove words with length less than 2\n",
    "    text = \" \".join([word for word in text.split() if len(word) > 1])\n",
    "    return text\n",
    "\n",
    "# Define a function that maps review scores to three labels\n",
    "def score_to_label(score):\n",
    "    if score >= 4:\n",
    "        return 2\n",
    "    elif score == 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Load dataset\n",
    "combined_review = pd.read_excel('combined_review.xlsx')\n",
    "\n",
    "# Preprocess reviews\n",
    "combined_review['제목_본문'] = combined_review['제목_본문'].apply(preprocess)\n",
    "combined_review['별점'] = combined_review['별점'].apply(score_to_label)\n",
    "\n",
    "sentences = combined_review['제목_본문']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4faa5f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]amazing producti travel lot and frequently stay at hotels in asia that feature bidet style toilet seat have long considered installing one at home and finally overcame inertia and purchased the washlet c2 this is an amazing product it makes this very necessary personal chore more pleasant more hygienic and dare say it more fun installation is very easy recommend this version with the remote control for ease of use units with the controls mounted on the side of the seat require phenomenal degree of agility to operate this washlet model was neither the cheapest nor the most expensive but think it is the highest value for money am totally impressed by the high degree of design and build quality in this product which says lot because am tough to impress engineer[SEP]',\n",
       " '[CLS]husband says best gift everi purchased this for my husband who fell in love with this product at hotel it was easy to install and he loves this seat weve had it for few months and he continues to report it is the best gift ive ever given him[SEP]',\n",
       " '[CLS]leakage problem fix72418first of did not buy mine from amazon bought it from an authorized distributor bought the round versionthings that like fits my kohler round toilet perfectly no overhang pressure is adequate for me but it requires to be at its highest setting this has less pressure in comparison to manual bidets or other competitors ymmv warm seat but im only going to use this during winter monthsthings that dont like it took me about hrs to install it due to the leakage have to drive to the store to buy washer to replace the one toto hasheres the fix that worked for me the blue oring that comes with the junction valve valve does not provide good seal so bought one from dales hardware see attached photo its an assorted aerator washer assorted black rings the blue rings in the pic are the original orings that came from toto they dont cost much only one black ring worked for me though that one has the similar size with that of the original blue oring but about mm thicker you can experiment what works for you but it did stopped the pesky leakage issue the seat wiggles little bit side to side but not significant for it to be dealbreaker the toilet hole is little bit small compare to what im used to the openclose control only works with the toilet seat doesnt control the toilet lid expensive comments havent experienced that it is noisy compare to other people havent tested the deodorizer didnt need sensor cover despite opening the door of the restroom nor coming in to wash my face in the sink it did not trigger the sensor although coming directly would automatically open the seat still turned off the feature because theres no wall separating the bathroom and restroom im satisfied despite the cons will update after year of using this[SEP]',\n",
       " '[CLS]loved it for the few days it has workedwe bought the bb2000 in mid november by the end of the month the bidet stopped working the lights on the seat began flashing the sequence once energysaver and flashes power the remote just beeps the warm air works the purifier works and the seat will sometimes stay warm sometimes not but no sprayers work this is so disappointing we had the outlet checked just to be sure and its all functioning properlyit seems like maybe this model had defective batch of parts or something because im reading others having this issuethe company is working well with us and sent new remote which didnt fix the problem then sent whole new seatthe second seat began having the same issue within 48 hours we are now waiting on third seat this basically has become vicious cycle already and im worried we will be constantly replacing the seat but never ever having fully working seat fear this repeats til the day the warranty expiresi will update with how we like it if it ever works properlytrying to find out if we can just return as defective to amazoncrossing our fingers[SEP]',\n",
       " '[CLS]it works beautifullyit does everything it says has many extra options beyond others self cleaning water continuously warm to your exact settings adj heated seat adjustable position for spray for that just right cleaning etcetcit was so easy to install was done and using in about 20 minutes had quick question for customer service and real person answered and answered my question quickly worth every penny over cheaper models[SEP]',\n",
       " '[CLS]favorite bathroom devicethis is cant live without device never constipated with the bb 2000 helps you go in the morning without the extra minutes of pushing cleans you out like roto rooter highly recommended[SEP]',\n",
       " '[CLS]was easy to installbought of these and couldnt be more happy good price and all the features you could ask for[SEP]',\n",
       " '[CLS]extremely helpful if you have constipation or hemorrhoidsthe best product we have bought for last year[SEP]',\n",
       " '[CLS]this was so easy for me to install no leaks and ready to go no tools where needed my husband is suffering from rectal cancer and this is dream come true for him he loves it no more toilet paper and soothing thank you biobidet for this amazing product[SEP]',\n",
       " '[CLS]broke too soonbroke way too soon now we have to spend money to replace it[SEP]']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 추출\n",
    "sentences = combined_review['제목_본문']\n",
    "sentences = [\"[CLS]\" + str(review) + \"[SEP]\" for review in combined_review['제목_본문']]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56b579d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 별점 추출\n",
    "labels = combined_review['별점'].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8671794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]amazing producti travel lot and frequently stay at hotels in asia that feature bidet style toilet seat have long considered installing one at home and finally overcame inertia and purchased the washlet c2 this is an amazing product it makes this very necessary personal chore more pleasant more hygienic and dare say it more fun installation is very easy recommend this version with the remote control for ease of use units with the controls mounted on the side of the seat require phenomenal degree of agility to operate this washlet model was neither the cheapest nor the most expensive but think it is the highest value for money am totally impressed by the high degree of design and build quality in this product which says lot because am tough to impress engineer[SEP]\n",
      "['[CLS]', 'ama', '##zing', 'product', '##i', 'travel', 'lot', 'and', 'frequently', 'stay', 'at', 'hotels', 'in', 'asi', '##a', 'that', 'feature', 'bid', '##et', 'style', 'toile', '##t', 'seat', 'have', 'long', 'considered', 'instal', '##ling', 'one', 'at', 'home', 'and', 'finally', 'over', '##cam', '##e', 'in', '##erti', '##a', 'and', 'purchased', 'the', 'was', '##hle', '##t', 'c', '##2', 'this', 'is', 'an', 'ama', '##zing', 'product', 'it', 'makes', 'this', 'very', 'necessary', 'personal', 'cho', '##re', 'more', 'pl', '##eas', '##ant', 'more', 'hy', '##gien', '##ic', 'and', 'dare', 'say', 'it', 'more', 'fun', 'installation', 'is', 'very', 'easy', 're', '##com', '##mend', 'this', 'version', 'with', 'the', 'remote', 'control', 'for', 'ea', '##se', 'of', 'use', 'units', 'with', 'the', 'controls', 'mounted', 'on', 'the', 'side', 'of', 'the', 'seat', 'require', 'ph', '##enomena', '##l', 'degree', 'of', 'ag', '##ility', 'to', 'operate', 'this', 'was', '##hle', '##t', 'model', 'was', 'neither', 'the', 'che', '##ap', '##est', 'nor', 'the', 'most', 'expensive', 'but', 'think', 'it', 'is', 'the', 'highest', 'value', 'for', 'money', 'am', 'totally', 'impressed', 'by', 'the', 'high', 'degree', 'of', 'design', 'and', 'build', 'quality', 'in', 'this', 'product', 'which', 'says', 'lot', 'because', 'am', 'tou', '##gh', 'to', 'im', '##press', 'engineer', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "print(sentences[0])\n",
    "print(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efb40bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,  28149,  19308,  21535,  10116,  23595,  19826,  10111,\n",
       "        28846,  29597,  10160,  82102,  10106,  21744,  10113,  10189,\n",
       "        19072,  50385,  10308,  13351,  63131,  10123,  17687,  10529,\n",
       "        11695,  14289,  50562,  11945,  10464,  10160,  11816,  10111,\n",
       "        21256,  10491,  67354,  10112,  10106,  49366,  10113,  10111,\n",
       "        24463,  10105,  10134,  41058,  10123,    171,  10729,  10531,\n",
       "        10124,  10151,  28149,  19308,  21535,  10271,  20562,  10531,\n",
       "        12558,  27039,  14927,  11257,  10246,  10798,  20648,  42658,\n",
       "        11236,  10798,  15165,  55713,  11130,  10111,  45476,  23763,\n",
       "        10271,  10798,  41807,  38639,  10124,  12558,  44346,  11639,\n",
       "        22530, 101480,  10531,  11674,  10169,  10105,  55808,  12608,\n",
       "        10142,  22257,  10341,  10108,  11760,  17163,  10169,  10105,\n",
       "        59897,  44709,  10135,  10105,  12250,  10108,  10105,  17687,\n",
       "        35742,  99142, 102523,  10161,  16455,  10108,  16942,  44704,\n",
       "        10114,  34307,  10531,  10134,  41058,  10123,  13192,  10134,\n",
       "        51148,  10105,  10262,  16070,  13051,  31515,  10105,  10992])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 토큰의 최대 시퀀스 길이\n",
    "MAX_LEN = 128\n",
    "\n",
    "# 토큰을 숫자 인덱스로 변환\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f7d50e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 마스크 초기화\n",
    "attention_masks = []\n",
    "\n",
    "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1900b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101, 10192, 20390, 44346, 50562, 91177, 12563, 10157, 20648, 42658,\n",
      "        10336, 24463, 10551, 10142, 17446, 11816, 10111, 11059, 10464, 10142,\n",
      "        15127, 10312, 11155, 10301, 12403, 13190, 10111, 15127, 43310, 10106,\n",
      "        10105, 27657, 10319, 15433, 10551, 33003, 37247, 10107, 14009, 14772,\n",
      "        10142, 10911, 10111, 10105, 13190, 22153, 10271, 14009, 15198, 10142,\n",
      "        11345,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       dtype=torch.int32)\n",
      "tensor(2)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([  101, 10134, 14541, 56126, 13192, 22897, 25611, 15774, 10105, 56126,\n",
      "        13192, 10134, 14541, 23782, 91978, 10192, 10457, 10472, 15688, 25287,\n",
      "        10133, 10211, 54214, 10169, 10105, 37891, 10111, 10146, 25212, 44346,\n",
      "        10114, 50562, 10161, 10111, 11760,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0],\n",
      "       dtype=torch.int32)\n",
      "tensor(2)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# 훈련셋과 검증셋으로 분리\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=324, test_size=0.2)\n",
    "\n",
    "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
    "                                                       input_ids,\n",
    "                                                       random_state=324, \n",
    "                                                       test_size=0.2)\n",
    "\n",
    "# 데이터를 파이토치의 텐서로 변환\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
    "\n",
    "print(train_inputs[0])\n",
    "print(train_labels[0])\n",
    "print(train_masks[0])\n",
    "print(validation_inputs[0])\n",
    "print(validation_labels[0])\n",
    "print(validation_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7541234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29000665",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "603a016e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10512\\2277491468.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Found GPU at: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU device not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "# GPU 디바이스 이름 구함\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# GPU 디바이스 이름 검사\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03e81c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03cae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5347583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c8698cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10512\\857824214.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 분류를 위한 BERT 모델 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bert-base-multilingual-cased\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    903\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m         \"\"\"\n\u001b[1;32m--> 905\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 820\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    903\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m         \"\"\"\n\u001b[1;32m--> 905\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# 분류를 위한 BERT 모델 생성\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3c2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff00e4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6204f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e424397a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f006326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e0c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d484eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6439f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf95ba33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fafb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 디바이스 이름 구함\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# GPU 디바이스 이름 검사\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f735248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c572a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1188eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465986c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebfc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597a442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6bdc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733d592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06e9d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a93a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(scaled_data, train_size=, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b9d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스로 훈련셋과 테스트셋 데이터 로드\n",
    "train = pd.read_csv(\"nsmc/ratings_train.txt\", sep='\\t')\n",
    "test = pd.read_csv(\"nsmc/ratings_test.txt\", sep='\\t')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 훈련셋의 앞부분 출력\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed139fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 문장 추출\n",
    "sentences = train['document']\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT의 입력 형식에 맞게 변환\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecdd20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 라벨 추출\n",
    "labels = train['label'].values\n",
    "labels\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e358e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "print (sentences[0])\n",
    "print (tokenized_texts[0])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d23d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 토큰의 최대 시퀀스 길이\n",
    "MAX_LEN = 128\n",
    "\n",
    "# 토큰을 숫자 인덱스로 변환\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbded5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfb771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4383697c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa4cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "751.179px",
    "left": "120px",
    "top": "134.144px",
    "width": "481.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
